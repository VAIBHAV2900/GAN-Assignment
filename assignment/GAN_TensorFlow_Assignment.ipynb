{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTly3EH-MmRe"
      },
      "source": [
        "# Mounting drive\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "files.upload() #this will prompt you to upload the kaggle.json\n",
        "# after uploading the .json file you will get your kaggle username and key as output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68wBceXQN5jP"
      },
      "source": [
        "!pip3 install kaggle\n",
        "\n",
        "%env KAGGLE_USERNAME = \"\"  # enter username and key without \"\" (i.e. remove \"\")\n",
        "%env KAGGLE_KEY = \"\"   \n",
        "\n",
        "# go to your dataset and click the \"copy API command\" and paste below with an \"!\" in the front-\n",
        "\n",
        "# replace \"filename\" with your downloaded filename\n",
        "!unzip File Name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXKkB2mKGZ_A"
      },
      "source": [
        "# Importing stuff\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from matplotlib import pyplot\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7ENPTdqGdom"
      },
      "source": [
        "# Defining some global variable\n",
        "IMG_H = 64\n",
        "IMG_W = 64\n",
        "IMG_C = 3\n",
        "latent_dim = 128 # hyper parameter\n",
        "w_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02) # weight initialization "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKpRuCqcG0GH"
      },
      "source": [
        "#########################################################################################################################################################\n",
        "#TODO write the load_image() that takes image_path as input and resizes the image to 64x64x3 with every pixel normalized to (-1, 1), dont forget to convert the image to tf.float32\n",
        "# Use only tensorflow to process the image                                                                       \n",
        "def load_image(image_path):\n",
        "  \n",
        "    return img\n",
        "# funtion for making dataset\n",
        "def tf_dataset(images_path, batch_size):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(images_path)\n",
        "    dataset = dataset.shuffle(buffer_size=10240)\n",
        "    dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQEor7sbHNG9"
      },
      "source": [
        "###########################################################################################################################################################\n",
        "################################################################## Write your discriminator ###############################################################\n",
        "\n",
        "discriminator = keras.Sequential([\n",
        "    ], name = \"discriminator\"\n",
        "    )\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNoLNhK-J8J_"
      },
      "source": [
        "###########################################################################################################################################################\n",
        "################################################################## Write your generator ###################################################################\n",
        "\n",
        "generator = keras.Sequential([\n",
        "    ], name = \"generator\"\n",
        "    )\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDpSkjEXKH82"
      },
      "source": [
        "#defining GAN class with modified train_step function.\n",
        "class GAN(Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        \n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "\n",
        "            ## Train the discriminator\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "        generated_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        with tf.GradientTape() as ftape:\n",
        "            predictions = self.discriminator(generated_images)\n",
        "            d1_loss = self.loss_fn(generated_labels, predictions)\n",
        "        grads = ftape.gradient(d1_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "            ## Train the discriminator\n",
        "        labels = tf.ones((batch_size, 1))\n",
        "\n",
        "        with tf.GradientTape() as rtape:\n",
        "            predictions = self.discriminator(real_images)\n",
        "            d2_loss = self.loss_fn(labels, predictions)\n",
        "        grads = rtape.gradient(d2_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "        ## Train the generator\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        misleading_labels = tf.ones((batch_size, 1))\n",
        "\n",
        "        with tf.GradientTape() as gtape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = gtape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        return {\"d1_loss\": d1_loss, \"d2_loss\": d2_loss, \"g_loss\": g_loss}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFGT19xOKW4m"
      },
      "source": [
        "# function for saving plots \n",
        "def save_plot(examples, epoch, n):\n",
        "    examples = (examples + 1) / 2.0\n",
        "    for i in range(n * n):\n",
        "        pyplot.subplot(n, n, i+1)\n",
        "        pyplot.axis(\"off\")\n",
        "        pyplot.imshow(examples[i])  \n",
        "    filename = f\"samples/generated_plot_epoch-{epoch+1}.png\"  # edit this as you like just make sure \"samples\"  folder exists in the current working directory\n",
        "    pyplot.savefig(filename)\n",
        "    pyplot.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCO7vJ8HKf9G"
      },
      "source": [
        "# main function containing all funtcion calls and hyper paramerters\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ## Hyperparameters\n",
        "    batch_size = 128\n",
        "    num_epochs = 80\n",
        "    images_path = glob(\"archive/images/*\") #image path\n",
        "    \n",
        "    #discriminator.load_weights(\"saved_model/d_model.h5\")\n",
        "    #generator.load_weights(\"saved_model/g_model.h5\")\n",
        "    \n",
        "    gan = GAN(discriminator, generator, latent_dim)\n",
        "# loss function and optimizers\n",
        "    bce_loss_fn =   # TODO define a loss function\n",
        "    d_optimizer =   # TODO define discriminator optimizer\n",
        "    g_optimizer =   # TODO define generator optimizer\n",
        "# Compiling\n",
        "    gan.compile(d_optimizer, g_optimizer, bce_loss_fn)\n",
        "\n",
        "    images_dataset = tf_dataset(images_path, batch_size)\n",
        "# training\n",
        "    for epoch in range(num_epochs):\n",
        "        gan.fit(images_dataset, epochs=1)\n",
        "        generator.save(\"saved_model/g_model.h5\")\n",
        "        discriminator.save(\"saved_model/d_model.h5\")\n",
        "\n",
        "        n_samples = 25\n",
        "        noise = np.random.normal(size=(n_samples, latent_dim))\n",
        "        examples = generator.predict(noise)\n",
        "        save_plot(examples, epoch, int(np.sqrt(n_samples)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}